{
 "metadata": {
  "name": "",
  "signature": "sha256:9ebb2d6821a03ee956d0c461e89f57355b828a27968125ae110676732f76437b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import pandas as pd\n",
      "from random import shuffle\n",
      "\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.metrics import classification_report,confusion_matrix\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from nltk.classify.scikitlearn import SklearnClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TRAINING_SET_SIZE = 10000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"data/train.tsv\",sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.drop([\"PhraseId\",\"SentenceId\"],axis=1,inplace=True) # remove useless columns\n",
      "df.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Phrase</th>\n",
        "      <th>Sentiment</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>156055</th>\n",
        "      <td>                 Hearst 's</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>156056</th>\n",
        "      <td> forced avuncular chortles</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>156057</th>\n",
        "      <td>        avuncular chortles</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>156058</th>\n",
        "      <td>                 avuncular</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>156059</th>\n",
        "      <td>                  chortles</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 183,
       "text": [
        "                           Phrase  Sentiment\n",
        "156055                  Hearst 's          2\n",
        "156056  forced avuncular chortles          1\n",
        "156057         avuncular chortles          3\n",
        "156058                  avuncular          2\n",
        "156059                   chortles          2"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_all = df.copy(deep=True)\n",
      "filtered_cols = ((df.Sentiment == 0) | (df.Sentiment == 4))\n",
      "df = df[filtered_cols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Phrase</th>\n",
        "      <th>Sentiment</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>63 </th>\n",
        "      <td> This quiet , introspective and entertaining in...</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66 </th>\n",
        "      <td> quiet , introspective and entertaining indepen...</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>74 </th>\n",
        "      <td>                                      entertaining</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>77 </th>\n",
        "      <td>                                  is worth seeking</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101</th>\n",
        "      <td>   would have a hard time sitting through this one</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 185,
       "text": [
        "                                                Phrase  Sentiment\n",
        "63   This quiet , introspective and entertaining in...          4\n",
        "66   quiet , introspective and entertaining indepen...          4\n",
        "74                                        entertaining          4\n",
        "77                                    is worth seeking          4\n",
        "101    would have a hard time sitting through this one          0"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dialogue_act_features(sentence):\n",
      "    \"\"\"Extracts a set of features from a message. \"\"\"\n",
      "    features = {}\n",
      "    tokens = nltk.word_tokenize(sentence)\n",
      "    for t in tokens:\n",
      "        features['contains(%s)' % t.lower()] = True    \n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featuresets =[]\n",
      "for row in df.head(TRAINING_SET_SIZE).iterrows():\n",
      "    text = row[1].Phrase\n",
      "    label = row[1].Sentiment\n",
      "    featuresets.append((dialogue_act_features(text),label))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classif = SklearnClassifier(LinearSVC())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#a_train, a_test, b_train, b_test = train_test_split(a, b, test_size=0.2, random_state=42)\n",
      "shuffle(featuresets)\n",
      "size = int(len(featuresets) * .2) # 10% is used for the test set\n",
      "train = featuresets[size:]\n",
      "test = featuresets[:size]\n",
      "print \"training size: {} testing size: {}\".format(len(train),len(test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "training size: 8000 testing size: 2000\n"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classif.train(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 190,
       "text": [
        "<SklearnClassifier(LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0))>"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_skl = []\n",
      "t_test_skl = []\n",
      "for d in test:\n",
      " test_skl.append(d[0])\n",
      " t_test_skl.append(d[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# run the classifier on the train test\n",
      "p = classif.classify_many(test_skl)\n",
      "print classification_report(t_test_skl, p, labels=list(set(t_test_skl)),target_names=['0','4'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.95      0.92      0.93       889\n",
        "          4       0.93      0.96      0.95      1111\n",
        "\n",
        "avg / total       0.94      0.94      0.94      2000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# so clearly if i just filter out sentiment using 0/4 I was able to construct a pretty decient\n",
      "# classifier, but how does it work if we look at the other classes\n",
      "confusion_matrix(t_test_skl, p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 193,
       "text": [
        "array([[ 814,   75],\n",
        "       [  44, 1067]])"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test = pd.read_csv(\"data/test.tsv\",sep=\"\\t\")\n",
      "df_test.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PhraseId</th>\n",
        "      <th>SentenceId</th>\n",
        "      <th>Phrase</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 156061</td>\n",
        "      <td> 8545</td>\n",
        "      <td> An intermittently pleasing but mostly routine ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 156062</td>\n",
        "      <td> 8545</td>\n",
        "      <td> An intermittently pleasing but mostly routine ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 156063</td>\n",
        "      <td> 8545</td>\n",
        "      <td>                                                An</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 156064</td>\n",
        "      <td> 8545</td>\n",
        "      <td> intermittently pleasing but mostly routine effort</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 156065</td>\n",
        "      <td> 8545</td>\n",
        "      <td>        intermittently pleasing but mostly routine</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 194,
       "text": [
        "   PhraseId  SentenceId                                             Phrase\n",
        "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
        "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
        "2    156063        8545                                                 An\n",
        "3    156064        8545  intermittently pleasing but mostly routine effort\n",
        "4    156065        8545         intermittently pleasing but mostly routine"
       ]
      }
     ],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_features = []\n",
      "for row in df_test.iterrows():\n",
      "    text = row[1].Phrase\n",
      "    test_features.append(dialogue_act_features(text))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = classif.classify_many(test_features);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 196
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"data/train.tsv\",sep='\\t')\n",
      "len(df),len(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 204,
       "text": [
        "(156060, 156060)"
       ]
      }
     ],
     "prompt_number": 204
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featuresets =[]\n",
      "for row in df.iterrows():\n",
      "    text = row[1].Phrase\n",
      "    label = row[1].Sentiment\n",
      "    featuresets.append((dialogue_act_features(text),label))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(5):\n",
      "    shuffle(featuresets)\n",
      "    size = int(len(featuresets) * .2) # 10% is used for the test set\n",
      "    train = featuresets[size:]\n",
      "    test = featuresets[:size]\n",
      "    print \"training size: {} testing size: {}\".format(len(train),len(test))\n",
      "    \n",
      "    test_skl = []\n",
      "    t_test_skl = []\n",
      "    for d in test:\n",
      "        test_skl.append(d[0])\n",
      "        t_test_skl.append(d[1])\n",
      "    \n",
      "    # run the classifier on the train test\n",
      "    p = classif.classify_many(test_skl)\n",
      "    print classification_report(t_test_skl, p, labels=list(set(t_test_skl)),target_names=['0','1','2','3','4'])\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "training size: 124848 testing size: 31212\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.11      0.91      0.19      1378\n",
        "          1       0.00      0.00      0.00      5493\n",
        "          2       0.00      0.00      0.00     15785\n",
        "          3       0.00      0.00      0.00      6661\n",
        "          4       0.09      0.97      0.17      1895\n",
        "\n",
        "avg / total       0.01      0.10      0.02     31212\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training size: 124848 testing size: 31212"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.11      0.93      0.20      1425\n",
        "          1       0.00      0.00      0.00      5483\n",
        "          2       0.00      0.00      0.00     15848\n",
        "          3       0.00      0.00      0.00      6663\n",
        "          4       0.09      0.96      0.16      1793\n",
        "\n",
        "avg / total       0.01      0.10      0.02     31212\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training size: 124848 testing size: 31212"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.11      0.92      0.20      1396\n",
        "          1       0.00      0.00      0.00      5513\n",
        "          2       0.00      0.00      0.00     15952\n",
        "          3       0.00      0.00      0.00      6524\n",
        "          4       0.09      0.96      0.17      1827\n",
        "\n",
        "avg / total       0.01      0.10      0.02     31212\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training size: 124848 testing size: 31212"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.10      0.91      0.19      1326\n",
        "          1       0.00      0.00      0.00      5379\n",
        "          2       0.00      0.00      0.00     15954\n",
        "          3       0.00      0.00      0.00      6673\n",
        "          4       0.09      0.96      0.17      1880\n",
        "\n",
        "avg / total       0.01      0.10      0.02     31212\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training size: 124848 testing size: 31212"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.11      0.91      0.20      1441\n",
        "          1       0.00      0.00      0.00      5427\n",
        "          2       0.00      0.00      0.00     16019\n",
        "          3       0.00      0.00      0.00      6494\n",
        "          4       0.09      0.96      0.17      1831\n",
        "\n",
        "avg / total       0.01      0.10      0.02     31212\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "confusion_matrix(t_test_skl, p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 207,
       "text": [
        "array([[ 1305,     0,     0,     0,   136],\n",
        "       [ 3626,     0,     0,     0,  1801],\n",
        "       [ 5622,     0,     0,     0, 10397],\n",
        "       [ 1118,     0,     0,     0,  5376],\n",
        "       [   71,     0,     0,     0,  1760]])"
       ]
      }
     ],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 203,
       "text": [
        "array([1, 2, 3, 4, 0])"
       ]
      }
     ],
     "prompt_number": 203
    }
   ],
   "metadata": {}
  }
 ]
}